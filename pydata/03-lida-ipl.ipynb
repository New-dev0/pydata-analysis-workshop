{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Project LIDA\n",
    "\n",
    "LIDA is a library for generating data visualizations and data-faithful infographics. LIDA is grammar agnostic (will work with any programming language and visualization libraries e.g. matplotlib, seaborn, altair, d3 etc) and works with multiple large language model providers (OpenAI, Azure OpenAI, PaLM, Cohere, Huggingface).Details on the components of LIDA are described in [this paper](https://arxiv.org/abs/2303.02927) - star [this project](https://aka.ms/lida/github) for updates. \n",
    "\n",
    "LIDA _treats visualizations as code_ and provides a clean api for generating, executing, editing, explaining, evaluating and repairing visualization code. Here are some tasks you can execute with LIDA.\n",
    "\n",
    "- ✅ Data Summarization\n",
    "- ✅ Goal Generation\n",
    "- ✅ Visualization Generation\n",
    "- ⬜️ Visualization Editing\n",
    "- ✅ Visualization Explanation\n",
    "- ⬜️ Visualization Evaluation and Repair\n",
    "- ✅ Visualization Recommendation\n",
    "- ⬜️ Infographic Generation (beta) # pip install lida[infographics]\n",
    "\n",
    "![LIDA Modules illustrated](https://github.com/microsoft/lida/raw/main/docs/images/lidamodules.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Summarization\n",
    "Given a dataset, generate a compact summary of that data in a compact natural language representation that serves as context for subsequent tasks. The goal of the summarizer is to _produce an dense-but-compact information summary for a given dataset that is useful as grounding context for visualization tasks_. The grounding context is defined as one that contains information an analyst would need to understand the dataset and the tasks that can be performed on it.\n",
    "\n",
    "See [paper](https://arxiv.org/pdf/2303.02927.pdf) for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from lida import Manager, TextGenerationConfig , llm  \n",
    "\n",
    "csvfile = \"./../data/kaggle/IPL-2022.csv\"\n",
    "lida = Manager(text_gen = llm(\"openai\")) # palm, cohere .\n",
    "textgen_config = TextGenerationConfig(n=1, temperature=0.5, model=\"gpt-3.5-turbo-0301\", use_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize\n",
    "summary = lida.summarize(csvfile)\n",
    "summary_data = list(summary.keys())\n",
    "for keys in summary_data:\n",
    "    print(keys, \":\", summary[keys])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Goal Generation\n",
    "\n",
    "Given the dataset \"context\" generated by the summarizer, the LLM must now _generate a question (hypothesis), a visualization (that addresses the question) and a rationale (for that visualization)_. The research found that requiring the LLM to produce a rationale led to more semantically meaningful goals.\n",
    "\n",
    "The generation API takes these parameters - the summary, the number of goals to generate (n) and a persona (optional) that influences the tone or context for the goals generated. And the textgen_config that configures parameters for the given model.\n",
    "\n",
    "See [paper](https://arxiv.org/pdf/2303.02927.pdf) for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 5 goals from the summary - with the persona is a fan of the Mumbai team\n",
    "goals = lida.goals(summary, n=5, textgen_config=textgen_config, persona=\"fam of the Mumbai team who wants to see their stats\") # exploratory data analysis\n",
    "\n",
    "# create a list of dictionaries containing the goal information\n",
    "import pandas as pd\n",
    "goal_list = []\n",
    "for goal in goals:\n",
    "    display(goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# generate 10 goals from the summary with default persona\n",
    "goals = lida.goals(summary, n=10, textgen_config=textgen_config,) # exploratory data analysis\n",
    "\n",
    "# create a list of dictionaries containing the goal information\n",
    "import pandas as pd\n",
    "goal_list = []\n",
    "for goal in goals:\n",
    "    goal_dict = {'Question': goal.question, 'Visualization': goal.visualization, 'Rationale': goal.rationale}\n",
    "    goal_list.append(goal_dict)\n",
    "df = pd.DataFrame(goal_list)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualization Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize A Goal \n",
    "charts = lida.visualize(summary=summary, goal=goals[0]) # exploratory data analysis\n",
    "print(\"Charts length:\", len(charts))\n",
    "charts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a Goal - and specify a library\n",
    "target = goals[2]\n",
    "library = \"matplotlib\"\n",
    "charts = lida.visualize(summary=summary, goal=target, library=library) # exploratory data analysis\n",
    "charts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize it again - and specify a different library and textgen_config (change temperature)\n",
    "target = goals[2]\n",
    "library = \"seaborn\"\n",
    "textgen_config = TextGenerationConfig(n=1, temperature=0.2, use_cache=True)\n",
    "charts = lida.visualize(summary=summary, goal=target,library=library,textgen_config=textgen_config) # exploratory data analysis\n",
    "charts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use natural language user query instead of pre-formulated goal\n",
    "user_query = \"What is the frequency of toss decisions based on team ?\"\n",
    "textgen_config = TextGenerationConfig(n=1, temperature=0.2, use_cache=True)\n",
    "charts = lida.visualize(summary=summary, goal=user_query, textgen_config=textgen_config)  \n",
    "charts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain visualization\n",
    "explanation = lida.explain(code=charts[0].code)\n",
    "for obj in explanation[0]:\n",
    "    display(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit visualization - modify using natural language -- insufficient tokens in model to run this\n",
    "#instructions = [\"change the color to green\", \"translate the title to french\"]\n",
    "# edited_charts = lida.edit(code=charts[0],  summary=summary, instructions=instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommend 3 visualizations \n",
    "recommendations = lida.recommend(code=charts[0].code, summary=summary, n=3,  textgen_config=textgen_config)\n",
    "\n",
    "for chart in recommendations:\n",
    "    display(chart) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"Who won the most cricket games? Use a colorful palette. Show the x-axis labels in a vertical orientation. Increase height of chart by 15%\"\n",
    "textgen_config = TextGenerationConfig(n=1, temperature=0.2, use_cache=True)\n",
    "charts = lida.visualize(summary=summary, goal=user_query, textgen_config=textgen_config, library=\"matplotlib\")  \n",
    "charts[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "189101fc34b85ec7417252a331b6b3ef556b71030ac1f6fe00bfbe1409305460"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
